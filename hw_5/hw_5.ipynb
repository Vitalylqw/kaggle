{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим работу с данными, которые были использованы в ДЗ 2 и 3, продолжим решать задачу обнаружения мошеннических транзакций, что позволит получить полное решение задачи / полный пайплайн.\n",
    "\n",
    "Задание 0: выбрать любую модель машнного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага.\n",
    "\n",
    "Задание 1: признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день.\n",
    "\n",
    "Задание 2: сделать конкатенацию признаков\n",
    "* card1 + card2;\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "Рассматривать их как категориальных признаки.\n",
    "\n",
    "Задание 3: Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2.\n",
    "\n",
    "Задание 4: Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2.\n",
    "\n",
    "Задание 5: Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2.\n",
    "\n",
    "Задание 6: выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt\n",
    "\n",
    "Задание 7 (опция): выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "from classes_and_functions import bootstrap_calculate_confidence_interval, make_cross_validation,make_cross_validation_gr\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.50</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.00</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.00</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.00</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179995</th>\n",
       "      <td>3166995</td>\n",
       "      <td>0</td>\n",
       "      <td>3958217</td>\n",
       "      <td>39.00</td>\n",
       "      <td>W</td>\n",
       "      <td>1877</td>\n",
       "      <td>310.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179996</th>\n",
       "      <td>3166996</td>\n",
       "      <td>0</td>\n",
       "      <td>3958237</td>\n",
       "      <td>59.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10075</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179997</th>\n",
       "      <td>3166997</td>\n",
       "      <td>0</td>\n",
       "      <td>3958241</td>\n",
       "      <td>34.00</td>\n",
       "      <td>W</td>\n",
       "      <td>6053</td>\n",
       "      <td>122.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179998</th>\n",
       "      <td>3166998</td>\n",
       "      <td>0</td>\n",
       "      <td>3958260</td>\n",
       "      <td>59.00</td>\n",
       "      <td>W</td>\n",
       "      <td>7726</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179999</th>\n",
       "      <td>3166999</td>\n",
       "      <td>0</td>\n",
       "      <td>3958317</td>\n",
       "      <td>226.00</td>\n",
       "      <td>W</td>\n",
       "      <td>17480</td>\n",
       "      <td>528.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180000 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  \\\n",
       "0             2987000        0          86400           68.50         W   \n",
       "1             2987001        0          86401           29.00         W   \n",
       "2             2987002        0          86469           59.00         W   \n",
       "3             2987003        0          86499           50.00         W   \n",
       "4             2987004        0          86506           50.00         H   \n",
       "...               ...      ...            ...             ...       ...   \n",
       "179995        3166995        0        3958217           39.00         W   \n",
       "179996        3166996        0        3958237           59.95         W   \n",
       "179997        3166997        0        3958241           34.00         W   \n",
       "179998        3166998        0        3958260           59.00         W   \n",
       "179999        3166999        0        3958317          226.00         W   \n",
       "\n",
       "        card1  card2  card3       card4  card5  ... V330  V331  V332  V333  \\\n",
       "0       13926    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   \n",
       "1        2755  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   \n",
       "2        4663  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   \n",
       "3       18132  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   \n",
       "4        4497  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   \n",
       "...       ...    ...    ...         ...    ...  ...  ...   ...   ...   ...   \n",
       "179995   1877  310.0  150.0  mastercard  224.0  ...  NaN   NaN   NaN   NaN   \n",
       "179996  10075  514.0  150.0  mastercard  224.0  ...  NaN   NaN   NaN   NaN   \n",
       "179997   6053  122.0  150.0  mastercard  195.0  ...  NaN   NaN   NaN   NaN   \n",
       "179998   7726  555.0  150.0        visa  226.0  ...  NaN   NaN   NaN   NaN   \n",
       "179999  17480  528.0  150.0        visa  226.0  ...  NaN   NaN   NaN   NaN   \n",
       "\n",
       "        V334 V335 V336  V337  V338  V339  \n",
       "0        NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "1        NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "2        NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "3        NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "4        0.0  0.0  0.0   0.0   0.0   0.0  \n",
       "...      ...  ...  ...   ...   ...   ...  \n",
       "179995   NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "179996   NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "179997   NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "179998   NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "179999   NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[180000 rows x 394 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('TransactionID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2987000</th>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987001</th>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987002</th>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987003</th>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987004</th>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               isFraud  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "TransactionID                                                                   \n",
       "2987000              0          86400            68.5         W  13926    NaN   \n",
       "2987001              0          86401            29.0         W   2755  404.0   \n",
       "2987002              0          86469            59.0         W   4663  490.0   \n",
       "2987003              0          86499            50.0         W  18132  567.0   \n",
       "2987004              0          86506            50.0         H   4497  514.0   \n",
       "\n",
       "               card3       card4  card5   card6  ...  V330  V331  V332  V333  \\\n",
       "TransactionID                                    ...                           \n",
       "2987000        150.0    discover  142.0  credit  ...   NaN   NaN   NaN   NaN   \n",
       "2987001        150.0  mastercard  102.0  credit  ...   NaN   NaN   NaN   NaN   \n",
       "2987002        150.0        visa  166.0   debit  ...   NaN   NaN   NaN   NaN   \n",
       "2987003        150.0  mastercard  117.0   debit  ...   NaN   NaN   NaN   NaN   \n",
       "2987004        150.0  mastercard  102.0  credit  ...   0.0   0.0   0.0   0.0   \n",
       "\n",
       "              V334 V335  V336  V337  V338  V339  \n",
       "TransactionID                                    \n",
       "2987000        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987001        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987002        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987003        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987004        0.0  0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 393 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 180000 entries, 2987000 to 3166999\n",
      "Columns: 393 entries, isFraud to V339\n",
      "dtypes: float64(376), int64(3), object(14)\n",
      "memory usage: 541.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_features = train.select_dtypes(include=[np.object]).columns\n",
    "train[object_features]= train[object_features].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scors = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 0: выбрать любую модель машнного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    'num_leaves':45,\n",
    "    'max_depth':4,\n",
    "    'learning_rate':0.1,\n",
    "    'n_estimators':5000,\n",
    "    \"metric\": \"auc\",\n",
    "    \"n_jobs\": 15,\n",
    "    'reg_alpha':2,\n",
    "    'reg_lambda':2,\n",
    "    \"random_state\": 30,\n",
    "#     'device':\"gpu\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1967,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9965549735307786)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9527215435494588)])}))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['base','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1: признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionDT'] =  pd.to_datetime('2017-12-01') + pd.to_timedelta(train.TransactionDT,unit='S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "год, месяц, день недели, час, день."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_features= object_features.to_list()\n",
    "object_features.append('TransactionDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'] = train.TransactionDT.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train.TransactionDT.apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day'] =  train.TransactionDT.apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['hour'] = train.TransactionDT.apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weekday'] = train.TransactionDT.apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2707,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.998940405914203)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9507593011596603)])}))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 90,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['TransactionDT','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор на валидации упал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: сделать конкатенацию признаков\n",
    "* card1 + card2;\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['card1_card2'] = train.apply(lambda x: str(x.card1)+'_' + str(x.card2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['card1_card2_card_3_card_5'] =\\\n",
    "    train.apply(lambda x: str(x.card1_card2)+'_' + str(x.card3) + '_'+str(x.card4) + '_'+ str(x.card5) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['card1_card2_card_3_card_5_addr1_addr2'] =\\\n",
    "    train.apply(lambda x: str(x.card1_card2_card_3_card_5)+'_' + str(x.addr1) + '_'+str(x.addr2) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "object_features = object_features + ['card1_card2','card1_card2_card_3_card_5','card1_card2_card_3_card_5_addr1_addr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(935,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9956111496620772)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9467338184054748)])}))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['concate cards','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "скор на валидации упал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3: Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [ 'card1', 'card2', 'card3','card5' ,'card6', 'addr1', 'addr2']:\n",
    "    train[i] = train[i].map(train[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(938,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9977382164445812)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9478016265152199)])}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['FrequencyEncoder','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4: Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000     68.50\n",
       "2987001     29.00\n",
       "2987002     59.00\n",
       "2987003     50.00\n",
       "2987004     50.00\n",
       "            ...  \n",
       "3166995     39.00\n",
       "3166996     59.95\n",
       "3166997     34.00\n",
       "3166998     59.00\n",
       "3166999    226.00\n",
       "Name: TransactionAmt, Length: 180000, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [ 'card1', 'card2', 'card3','card5' ,'card6', 'addr1', 'addr2']:\n",
    "    name = 'TransactionAmt_mean_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['TransactionAmt'].mean())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "    train[name] = train.TransactionAmt/train[name] \n",
    "    name = 'TransactionAmt_std_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['TransactionAmt'].std())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "    train[name] = train.TransactionAmt/train[name] \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(919,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9979416803112372)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9483070336202258)])}))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['TransactionAmt_stats','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5: Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [ 'card1', 'card2', 'card3','card5' ,'card6', 'addr1', 'addr2']:\n",
    "    name = 'D15_mean_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['D15'].mean())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "    train[name] = train.TransactionAmt/train[name] \n",
    "    name = 'D15_std_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['D15'].std())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "    train[name] = train.TransactionAmt/train[name] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(974,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9982298205610648)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9482703728296701)])}))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['D15_stats','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6: выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_int'] = train.TransactionAmt//1\n",
    "train['TransactionAmt_float'] = train.TransactionAmt%1\n",
    "train['TransactionAmt_log'] = np.log(train.TransactionAmt+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1171,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9989245044336792)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9499363526396437)])}))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['TransactionAmt_new','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7 (опция): выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.P_emaildomain = train.P_emaildomain.map(train.P_emaildomain.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.P_emaildomain = train.P_emaildomain.map(train.P_emaildomain.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1065,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9986646301995645)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9496490188259558)])}))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['emaildomain_freq','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.952722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionDT</th>\n",
       "      <td>0.950759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concate cards</th>\n",
       "      <td>0.946734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrequencyEncoder</th>\n",
       "      <td>0.947802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionAmt_stats</th>\n",
       "      <td>0.948307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D15_stats</th>\n",
       "      <td>0.948270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionAmt_new</th>\n",
       "      <td>0.949936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emaildomain_freq</th>\n",
       "      <td>0.949649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           auc\n",
       "base                  0.952722\n",
       "TransactionDT         0.950759\n",
       "concate cards         0.946734\n",
       "FrequencyEncoder      0.947802\n",
       "TransactionAmt_stats  0.948307\n",
       "D15_stats             0.948270\n",
       "TransactionAmt_new    0.949936\n",
       "emaildomain_freq      0.949649"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранее мы накладывали новые признаки друг на друга. Теперь попробуем считать скор раздельно по каждому признаку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2707,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.998940405914203)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9507593289751312)])}))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train= pd.read_csv('train.csv')\n",
    "train.set_index('TransactionID',inplace=True)\n",
    "object_features = train.select_dtypes(include=[np.object]).columns\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "train['TransactionDT'] =  pd.to_datetime('2017-12-01') + pd.to_timedelta(train.TransactionDT,unit='S')\n",
    "object_features= object_features.to_list()\n",
    "object_features.append('TransactionDT')\n",
    "train['year'] = train.TransactionDT.apply(lambda x: x.year)\n",
    "train['month'] = train.TransactionDT.apply(lambda x: x.month)\n",
    "train['day'] =  train.TransactionDT.apply(lambda x: x.day)\n",
    "train['hour'] = train.TransactionDT.apply(lambda x: x.hour)\n",
    "train['weekday'] = train.TransactionDT.apply(lambda x: x.weekday())\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 90,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['TransactionDT','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1480,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.998448561945898)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9503510813097393)])}))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train= pd.read_csv('train.csv')\n",
    "train.set_index('TransactionID',inplace=True)\n",
    "object_features = train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "train['card1_card2'] = train.apply(lambda x: str(x.card1)+'_' + str(x.card2),axis=1)\n",
    "train['card1_card2_card_3_card_5'] =\\\n",
    "    train.apply(lambda x: str(x.card1_card2)+'_' + str(x.card3) + '_'+str(x.card4) + '_'+ str(x.card5) ,axis=1)\n",
    "train['card1_card2_card_3_card_5_addr1_addr2'] =\\\n",
    "    train.apply(lambda x: str(x.card1_card2_card_3_card_5)+'_' + str(x.addr1) + '_'+str(x.addr2) ,axis=1)\n",
    "\n",
    "object_features = object_features + ['card1_card2','card1_card2_card_3_card_5','card1_card2_card_3_card_5_addr1_addr2']\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['concate cards','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### № 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1821,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9958435452201528)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9504295209374837)])}))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train= pd.read_csv('train.csv')\n",
    "train.set_index('TransactionID',inplace=True)\n",
    "object_features = train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "for i in [ 'card1', 'card2', 'card3','card5' ,'card6', 'addr1', 'addr2']:\n",
    "    train[i] = train[i].map(train[i].value_counts())\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['FrequencyEncoder','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### № 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2056,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9986813016391954)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9502662719391745)])}))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train= pd.read_csv('train.csv')\n",
    "train.set_index('TransactionID',inplace=True)\n",
    "object_features = train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "for i in [ 'card1', 'card2', 'card3','card5' ,'card6', 'addr1', 'addr2']:\n",
    "    name = 'TransactionAmt_mean_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['TransactionAmt'].mean())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "    train[name] = train.TransactionAmt/train[name] \n",
    "    name = 'TransactionAmt_std_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['TransactionAmt'].std())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "    train[name] = train.TransactionAmt/train[name] \n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['TransactionAmt_stats','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### № 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1835,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9981319471135564)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9515854206433518)])}))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train= pd.read_csv('train.csv')\n",
    "train.set_index('TransactionID',inplace=True)\n",
    "object_features = train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "for i in [ 'card1', 'card2', 'card3','card5' ,'card6', 'addr1', 'addr2']:\n",
    "    name = 'D15_mean_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['D15'].mean())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "    train[name] = train.TransactionAmt/train[name] \n",
    "    name = 'D15_std_'+str(i)\n",
    "    train[name] = train[i].map(train.groupby(i)['D15'].std())\n",
    "    train[name] = train[name].astype(np.float64)\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['D15_stats','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### № 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1030,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9878944943493526)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9457054248178977)])}))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train= pd.read_csv('train.csv')\n",
    "train.set_index('TransactionID',inplace=True)\n",
    "object_features = train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "train['TransactionAmt_int'] = train.TransactionAmt//1\n",
    "train['TransactionAmt_float'] = train.TransactionAmt%1\n",
    "train['TransactionAmt_log'] = np.log(train.TransactionAmt+0.01)\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['TransactionAmt_new','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### № 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1450,\n",
       " defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9933170156577581)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9487687426205555)])}))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train= pd.read_csv('train.csv')\n",
    "train.set_index('TransactionID',inplace=True)\n",
    "object_features = train.select_dtypes(include=[np.object]).columns.to_list()\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "train.P_emaildomain = train.P_emaildomain.map(train.P_emaildomain.value_counts())\n",
    "train.P_emaildomain = train.P_emaildomain.map(train.P_emaildomain.value_counts())\n",
    "train[object_features]= train[object_features].astype(str)\n",
    "train[object_features]= train[object_features].astype('category')\n",
    "x_train,x_valid,y_train,y_valid =\\\n",
    "train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.2,random_state=30,stratify =train['isFraud'])\n",
    "model.fit(x_train,y_train,early_stopping_rounds  = 50,\\\n",
    "            eval_set =[(x_train,y_train),(x_valid,y_valid)],verbose = False)\n",
    "scors.loc['emaildomain_freq','auc'] = model.best_score_['valid_1']['auc']\n",
    "model.best_iteration_,model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.952722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionDT</th>\n",
       "      <td>0.950759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concate cards</th>\n",
       "      <td>0.950351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrequencyEncoder</th>\n",
       "      <td>0.950430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionAmt_stats</th>\n",
       "      <td>0.950266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D15_stats</th>\n",
       "      <td>0.951585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionAmt_new</th>\n",
       "      <td>0.945705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emaildomain_freq</th>\n",
       "      <td>0.948769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           auc\n",
       "base                  0.952722\n",
       "TransactionDT         0.950759\n",
       "concate cards         0.950351\n",
       "FrequencyEncoder      0.950430\n",
       "TransactionAmt_stats  0.950266\n",
       "D15_stats             0.951585\n",
       "TransactionAmt_new    0.945705\n",
       "emaildomain_freq      0.948769"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно ни один новый признак как вместе та ки по отдельности не увеличил качество моджели на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
